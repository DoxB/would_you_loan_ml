{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baehuijin/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 고정\n",
    "SEED = 2024\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>아파트매매지수</th>\n",
       "      <th>부동산심리지수</th>\n",
       "      <th>kospi</th>\n",
       "      <th>소비자물가지수</th>\n",
       "      <th>New_COFIX</th>\n",
       "      <th>Outstanding_COFIX</th>\n",
       "      <th>실업률</th>\n",
       "      <th>아파트거래량</th>\n",
       "      <th>지가변동률</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>122.9</td>\n",
       "      <td>2120.03</td>\n",
       "      <td>88.654</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.2</td>\n",
       "      <td>128.3</td>\n",
       "      <td>2160.09</td>\n",
       "      <td>89.250</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4931</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>121.7</td>\n",
       "      <td>1887.21</td>\n",
       "      <td>89.164</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4868</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.4</td>\n",
       "      <td>109.2</td>\n",
       "      <td>1683.94</td>\n",
       "      <td>89.079</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4701</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.6</td>\n",
       "      <td>100.4</td>\n",
       "      <td>1891.22</td>\n",
       "      <td>89.079</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4568</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>160.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2766.24</td>\n",
       "      <td>113.370</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>161.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2679.04</td>\n",
       "      <td>113.420</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5182</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>164.1</td>\n",
       "      <td>120.1</td>\n",
       "      <td>2657.81</td>\n",
       "      <td>113.170</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6150</td>\n",
       "      <td>0.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>167.6</td>\n",
       "      <td>123.5</td>\n",
       "      <td>2792.96</td>\n",
       "      <td>113.460</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9518</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>170.2</td>\n",
       "      <td>125.6</td>\n",
       "      <td>2787.27</td>\n",
       "      <td>113.940</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7609</td>\n",
       "      <td>0.282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     아파트매매지수  부동산심리지수    kospi  소비자물가지수  New_COFIX  Outstanding_COFIX  실업률  \\\n",
       "0       80.0    122.9  2120.03   88.654       3.42               3.69  4.2   \n",
       "1       80.2    128.3  2160.09   89.250       3.52               3.73  4.3   \n",
       "2       80.0    121.7  1887.21   89.164       3.56               3.74  4.4   \n",
       "3       79.4    109.2  1683.94   89.079       3.54               3.76  4.0   \n",
       "4       78.6    100.4  1891.22   89.079       3.59               3.78  4.0   \n",
       "..       ...      ...      ...      ...        ...                ...  ...   \n",
       "153    160.0    110.0  2766.24  113.370       3.71               3.95  3.6   \n",
       "154    161.4    113.0  2679.04  113.420       3.70               3.96  3.6   \n",
       "155    164.1    120.1  2657.81  113.170       3.77               3.96  3.3   \n",
       "156    167.6    123.5  2792.96  113.460       3.80               3.95  2.6   \n",
       "157    170.2    125.6  2787.27  113.940       3.70               3.93  2.4   \n",
       "\n",
       "     아파트거래량  지가변동률  \n",
       "0      4096  0.067  \n",
       "1      4931  0.052  \n",
       "2      4868  0.049  \n",
       "3      4701  0.043  \n",
       "4      4568  0.037  \n",
       "..      ...    ...  \n",
       "153    4840  0.238  \n",
       "154    5182  0.246  \n",
       "155    6150  0.269  \n",
       "156    9518  0.282  \n",
       "157    7609  0.282  \n",
       "\n",
       "[158 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 로드 및 전처리\n",
    "data = pd.read_csv('아파트매매지수예측_변수.csv').drop(columns='Unnamed: 0')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>아파트매매지수</th>\n",
       "      <th>부동산심리지수</th>\n",
       "      <th>kospi</th>\n",
       "      <th>소비자물가지수</th>\n",
       "      <th>New_COFIX</th>\n",
       "      <th>Outstanding_COFIX</th>\n",
       "      <th>실업률</th>\n",
       "      <th>아파트거래량</th>\n",
       "      <th>지가변동률</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.2</td>\n",
       "      <td>128.3</td>\n",
       "      <td>2160.09</td>\n",
       "      <td>89.250</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3.73</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4931</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>121.7</td>\n",
       "      <td>1887.21</td>\n",
       "      <td>89.164</td>\n",
       "      <td>3.56</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4868</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.4</td>\n",
       "      <td>109.2</td>\n",
       "      <td>1683.94</td>\n",
       "      <td>89.079</td>\n",
       "      <td>3.54</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4701</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.6</td>\n",
       "      <td>100.4</td>\n",
       "      <td>1891.22</td>\n",
       "      <td>89.079</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4568</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>77.7</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1911.50</td>\n",
       "      <td>89.335</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6207</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>160.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2766.24</td>\n",
       "      <td>113.370</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4840</td>\n",
       "      <td>0.238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>161.4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2679.04</td>\n",
       "      <td>113.420</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5182</td>\n",
       "      <td>0.246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>164.1</td>\n",
       "      <td>120.1</td>\n",
       "      <td>2657.81</td>\n",
       "      <td>113.170</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6150</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>167.6</td>\n",
       "      <td>123.5</td>\n",
       "      <td>2792.96</td>\n",
       "      <td>113.460</td>\n",
       "      <td>3.80</td>\n",
       "      <td>3.95</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9518</td>\n",
       "      <td>0.282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>170.2</td>\n",
       "      <td>125.6</td>\n",
       "      <td>2787.27</td>\n",
       "      <td>113.940</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7609</td>\n",
       "      <td>0.282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     아파트매매지수  부동산심리지수    kospi  소비자물가지수  New_COFIX  Outstanding_COFIX  실업률  \\\n",
       "1       80.2    128.3  2160.09   89.250       3.52               3.73  4.3   \n",
       "2       80.0    121.7  1887.21   89.164       3.56               3.74  4.4   \n",
       "3       79.4    109.2  1683.94   89.079       3.54               3.76  4.0   \n",
       "4       78.6    100.4  1891.22   89.079       3.59               3.78  4.0   \n",
       "5       77.7     99.0  1911.50   89.335       3.62               3.81  4.3   \n",
       "..       ...      ...      ...      ...        ...                ...  ...   \n",
       "153    160.0    110.0  2766.24  113.370       3.71               3.95  3.6   \n",
       "154    161.4    113.0  2679.04  113.420       3.70               3.96  3.6   \n",
       "155    164.1    120.1  2657.81  113.170       3.77               3.96  3.3   \n",
       "156    167.6    123.5  2792.96  113.460       3.80               3.95  2.6   \n",
       "157    170.2    125.6  2787.27  113.940       3.70               3.93  2.4   \n",
       "\n",
       "     아파트거래량  지가변동률  Target  \n",
       "1      4931  0.052       1  \n",
       "2      4868  0.049       0  \n",
       "3      4701  0.043       0  \n",
       "4      4568  0.037       0  \n",
       "5      6207  0.038       0  \n",
       "..      ...    ...     ...  \n",
       "153    4840  0.238       1  \n",
       "154    5182  0.246       1  \n",
       "155    6150  0.269       1  \n",
       "156    9518  0.282       1  \n",
       "157    7609  0.282       1  \n",
       "\n",
       "[157 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'] = (data['아파트매매지수'].diff() > 0).astype(int)  # 1 if increase, 0 if decrease\n",
    "\n",
    "data.drop(0, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant features and target\n",
    "features = data.drop(columns=['Target', '아파트매매지수'])\n",
    "target = data['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the time series data for LSTM\n",
    "def create_sequences(features, target, time_steps=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        X.append(features[i:i+time_steps])\n",
    "        y.append(target[i+time_steps])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Using the past 12 months to predict the next\n",
    "X, y = create_sequences(scaled_features, target.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145, 12, 8), (145,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets based on time (no shuffling)\n",
    "train_size = int(len(X) * 0.8)  # Use 80% for training\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baehuijin/Library/Python/3.9/lib/python/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(16, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(8, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.3847 - loss: 0.7302 - val_accuracy: 0.5000 - val_loss: 0.6929\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3309 - loss: 0.7151 - val_accuracy: 0.7727 - val_loss: 0.6794\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5675 - loss: 0.7132 - val_accuracy: 0.7727 - val_loss: 0.6617\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6761 - loss: 0.7145 - val_accuracy: 0.7727 - val_loss: 0.6489\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6999 - loss: 0.7161 - val_accuracy: 0.7727 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7474 - loss: 0.7294 - val_accuracy: 0.7727 - val_loss: 0.6261\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7649 - loss: 0.7307 - val_accuracy: 0.7727 - val_loss: 0.6307\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7745 - loss: 0.7170 - val_accuracy: 0.7727 - val_loss: 0.6331\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7433 - loss: 0.7130 - val_accuracy: 0.7727 - val_loss: 0.6361\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7273 - loss: 0.7127 - val_accuracy: 0.7727 - val_loss: 0.6412\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7273 - loss: 0.7034 - val_accuracy: 0.7727 - val_loss: 0.6466\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6805 - loss: 0.7037 - val_accuracy: 0.7727 - val_loss: 0.6323\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7437 - loss: 0.7052 - val_accuracy: 0.7727 - val_loss: 0.6137\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7433 - loss: 0.7166 - val_accuracy: 0.7727 - val_loss: 0.6023\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7307 - loss: 0.7152 - val_accuracy: 0.7727 - val_loss: 0.5964\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7009 - val_accuracy: 0.7727 - val_loss: 0.5958\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7433 - loss: 0.7114 - val_accuracy: 0.7727 - val_loss: 0.5967\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7112 - val_accuracy: 0.7727 - val_loss: 0.5994\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7399 - loss: 0.7226 - val_accuracy: 0.7727 - val_loss: 0.6032\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7433 - loss: 0.6957 - val_accuracy: 0.7727 - val_loss: 0.6028\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7415 - loss: 0.7003 - val_accuracy: 0.7727 - val_loss: 0.6014\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7329 - loss: 0.6987 - val_accuracy: 0.7727 - val_loss: 0.5962\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7347 - loss: 0.7047 - val_accuracy: 0.7727 - val_loss: 0.5953\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.6897 - val_accuracy: 0.7727 - val_loss: 0.5976\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.6872 - val_accuracy: 0.7727 - val_loss: 0.5975\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7143 - loss: 0.7049 - val_accuracy: 0.7727 - val_loss: 0.5920\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7433 - loss: 0.7023 - val_accuracy: 0.7727 - val_loss: 0.5909\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7329 - loss: 0.7015 - val_accuracy: 0.7727 - val_loss: 0.5904\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7224 - val_accuracy: 0.7727 - val_loss: 0.5920\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7421 - loss: 0.7162 - val_accuracy: 0.7727 - val_loss: 0.5995\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7015 - val_accuracy: 0.7727 - val_loss: 0.6073\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7109 - loss: 0.7095 - val_accuracy: 0.7727 - val_loss: 0.6069\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7181 - val_accuracy: 0.7727 - val_loss: 0.6037\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.7114 - val_accuracy: 0.7727 - val_loss: 0.6051\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7415 - loss: 0.7017 - val_accuracy: 0.7727 - val_loss: 0.6047\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7712 - loss: 0.6891 - val_accuracy: 0.7727 - val_loss: 0.5980\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7162 - loss: 0.7195 - val_accuracy: 0.7727 - val_loss: 0.5992\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7140 - loss: 0.7251 - val_accuracy: 0.7727 - val_loss: 0.6026\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7054 - loss: 0.7113 - val_accuracy: 0.7727 - val_loss: 0.5967\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7162 - loss: 0.7372 - val_accuracy: 0.7727 - val_loss: 0.5886\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7292 - loss: 0.6957 - val_accuracy: 0.7727 - val_loss: 0.5793\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.6759 - val_accuracy: 0.7727 - val_loss: 0.5775\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.6970 - val_accuracy: 0.7727 - val_loss: 0.5814\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7381 - loss: 0.6963 - val_accuracy: 0.7727 - val_loss: 0.5904\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7507 - loss: 0.6960 - val_accuracy: 0.7727 - val_loss: 0.5821\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7415 - loss: 0.6839 - val_accuracy: 0.7727 - val_loss: 0.5726\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7690 - loss: 0.6978 - val_accuracy: 0.7727 - val_loss: 0.5962\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7162 - loss: 0.7203 - val_accuracy: 0.7727 - val_loss: 0.6389\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7266 - loss: 0.6973 - val_accuracy: 0.7727 - val_loss: 0.6095\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7103 - loss: 0.7005 - val_accuracy: 0.7727 - val_loss: 0.5869\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7029 - loss: 0.6745 - val_accuracy: 0.7727 - val_loss: 0.6195\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6386 - loss: 0.6891 - val_accuracy: 0.7727 - val_loss: 0.6303\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6007 - loss: 0.6837 - val_accuracy: 0.7273 - val_loss: 0.6119\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6509 - loss: 0.6725 - val_accuracy: 0.7273 - val_loss: 0.6704\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5874 - loss: 0.6661 - val_accuracy: 0.2273 - val_loss: 0.7331\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6331 - loss: 0.6328 - val_accuracy: 0.3636 - val_loss: 0.7102\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4692 - loss: 0.6876 - val_accuracy: 0.2273 - val_loss: 0.7481\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5116 - loss: 0.6348 - val_accuracy: 0.6818 - val_loss: 0.6635\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5873 - loss: 0.6660 - val_accuracy: 0.2273 - val_loss: 0.7550\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5588 - loss: 0.6642 - val_accuracy: 0.7727 - val_loss: 0.6369\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6326 - loss: 0.7084 - val_accuracy: 0.2273 - val_loss: 0.7334\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4917 - loss: 0.7012 - val_accuracy: 0.2273 - val_loss: 0.7067\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6579 - loss: 0.6453 - val_accuracy: 0.8182 - val_loss: 0.6213\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7040 - loss: 0.7197 - val_accuracy: 0.7727 - val_loss: 0.6751\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6330 - loss: 0.6714 - val_accuracy: 0.7727 - val_loss: 0.6454\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6768 - loss: 0.6495 - val_accuracy: 0.7273 - val_loss: 0.6756\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6780 - loss: 0.6217 - val_accuracy: 0.6364 - val_loss: 0.6886\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5594 - loss: 0.6421 - val_accuracy: 0.3636 - val_loss: 0.6953\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6416 - loss: 0.6525 - val_accuracy: 0.6818 - val_loss: 0.6864\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6379 - loss: 0.6267 - val_accuracy: 0.5000 - val_loss: 0.6829\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6668 - loss: 0.6394 - val_accuracy: 0.2273 - val_loss: 0.7128\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6509 - loss: 0.6172 - val_accuracy: 0.3636 - val_loss: 0.7037\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5439 - loss: 0.6749 - val_accuracy: 0.3182 - val_loss: 0.7179\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5606 - loss: 0.6338 - val_accuracy: 0.4091 - val_loss: 0.8341\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5082 - loss: 0.6878 - val_accuracy: 0.2273 - val_loss: 0.7407\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5703 - loss: 0.5970 - val_accuracy: 0.2727 - val_loss: 0.7356\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6100 - loss: 0.6085 - val_accuracy: 0.5909 - val_loss: 0.7906\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5490 - loss: 0.7987 - val_accuracy: 0.2273 - val_loss: 0.7463\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2318 - loss: 0.7534 - val_accuracy: 0.2273 - val_loss: 0.7313\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2668 - loss: 0.7101 - val_accuracy: 0.2273 - val_loss: 0.7088\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3199 - loss: 0.7002 - val_accuracy: 0.7727 - val_loss: 0.6820\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6553 - loss: 0.7019 - val_accuracy: 0.7727 - val_loss: 0.6568\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7014 - loss: 0.6910 - val_accuracy: 0.7727 - val_loss: 0.6370\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7251 - loss: 0.6946 - val_accuracy: 0.7727 - val_loss: 0.6200\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7690 - loss: 0.6982 - val_accuracy: 0.7727 - val_loss: 0.6060\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7616 - loss: 0.6869 - val_accuracy: 0.7727 - val_loss: 0.5959\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.7111 - val_accuracy: 0.7727 - val_loss: 0.5929\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7507 - loss: 0.7077 - val_accuracy: 0.7727 - val_loss: 0.5936\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.6918 - val_accuracy: 0.7727 - val_loss: 0.5952\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7452 - loss: 0.7120 - val_accuracy: 0.7727 - val_loss: 0.5940\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7656 - loss: 0.6931 - val_accuracy: 0.7727 - val_loss: 0.5919\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7616 - loss: 0.7123 - val_accuracy: 0.7727 - val_loss: 0.5906\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7690 - loss: 0.6959 - val_accuracy: 0.7727 - val_loss: 0.5908\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7452 - loss: 0.7214 - val_accuracy: 0.7727 - val_loss: 0.5901\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.6949 - val_accuracy: 0.7727 - val_loss: 0.5894\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.7000 - val_accuracy: 0.7727 - val_loss: 0.5915\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7229 - loss: 0.7194 - val_accuracy: 0.7727 - val_loss: 0.5915\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7541 - loss: 0.6965 - val_accuracy: 0.7727 - val_loss: 0.5917\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7214 - loss: 0.7139 - val_accuracy: 0.7727 - val_loss: 0.5907\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7452 - loss: 0.7254 - val_accuracy: 0.7727 - val_loss: 0.5903\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=1, class_weight=class_weights_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6667 - loss: 0.6229\n",
      "Test Accuracy: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.60710865],\n",
       "       [0.6066611 ],\n",
       "       [0.6062372 ],\n",
       "       [0.60559034],\n",
       "       [0.6049711 ],\n",
       "       [0.6045195 ],\n",
       "       [0.6041889 ],\n",
       "       [0.60398334],\n",
       "       [0.603867  ],\n",
       "       [0.60364956],\n",
       "       [0.6032587 ],\n",
       "       [0.6025825 ],\n",
       "       [0.6015541 ],\n",
       "       [0.6002521 ],\n",
       "       [0.5987898 ],\n",
       "       [0.5969661 ],\n",
       "       [0.5948833 ],\n",
       "       [0.5927058 ],\n",
       "       [0.5906749 ],\n",
       "       [0.5892362 ],\n",
       "       [0.5910041 ],\n",
       "       [0.60057336],\n",
       "       [0.6386304 ],\n",
       "       [0.6801288 ],\n",
       "       [0.6932098 ],\n",
       "       [0.7032297 ],\n",
       "       [0.7001121 ]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.6\n",
    "\n",
    "y_pred_prob[y_pred_prob < thr] = 0\n",
    "y_pred_prob[y_pred_prob >= thr] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(50.722222222222214, 0.5, 'True Label')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = confusion_matrix(y_test, y_pred_prob)\n",
    "\n",
    "sns.heatmap(cf, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score :  0.7368421052631579\n",
      "Accuracy :  0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_Score : \", f1_score(y_test, y_pred_prob))\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
